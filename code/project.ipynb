{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec8c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U \"langchain>=0.3.7,<0.4\" \"langchain-core>=0.3.15,<0.4\" langchain-openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ed99f",
   "metadata": {},
   "source": [
    "### Step 0: Prerequisites & Setup\n",
    "\n",
    "- Python 3.9+\n",
    "- a virtual environment\n",
    "- OpenAI API Key in .env as `OpenAI_API_KEY`\n",
    "- Sanity check for having access to OpenAI API and be able to run a simple chat completion via LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d79d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key loaded successfully!\n",
      "Your OpenAI API Key is:  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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv()\n",
    "    print(\"Environment variables loaded from .env file.\")\n",
    "\n",
    "\n",
    "# Access the API keys\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"OpenAI API Key loaded successfully!\")\n",
    "    print(\"Your OpenAI API Key is: \", api_key)\n",
    "\n",
    "else:\n",
    "    print(\"API Key not found. Please check your .env file.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f8c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to predict specific research topics for 2025, but I can suggest some areas that are likely to remain important based on trends up to 2023. These include:\n",
      "\n",
      "- **Artificial Intelligence and Machine Learning**: Continued advancements in AI, including explainable AI, reinforcement learning, and AI ethics, are expected to be key areas of focus.\n",
      "- **Quantum Computing**: Research into making quantum computing more practical and accessible for solving real-world problems is likely to remain a hot topic.\n",
      "- **Sustainability and Climate Change**: Efforts to develop technologies for renewable energy, carbon capture, and sustainable living practices will be crucial in addressing environmental challenges.\n",
      "- **Biotechnology and Healthcare Innovations**: Advances in personalized medicine, gene editing technologies like CRISPR, and new vaccine developments will continue to be important.\n",
      "- **Cybersecurity and Privacy**: As digital transformation expands, research on protecting data and ensuring privacy in a hyper-connected world will be vital.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Intialize chat model via LangChain\n",
    "chat = ChatOpenAI(model=\"gpt-4o\", temperature=0.8)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"What are the hot research topics in 2025? Return your answer in 5 sentences and in bullet points.\"),\n",
    "]\n",
    "\n",
    "print(chat.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec4ed1",
   "metadata": {},
   "source": [
    "### Step 1: Define the Agent State\n",
    "\n",
    "##### Create the Agent State Schema\n",
    "The `AgentState` defines what data flows through your graph.\n",
    "Each key is annotated with its reducer — here, we’re saying:\n",
    "> “For each node output, merge the new messages with the previous ones.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages] # Message history\n",
    "    system_prompt: SystemMessage   # System prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268442e",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the LLM and Bind Tools\n",
    "\n",
    "##### Choose the Chat Model:\n",
    "We use GPT-4 through the `ChatOpenAI` interface, setting a moderate `temperature=0.05` to prioritize consistent, reliable responses over creative variability.\n",
    "\n",
    "##### Choose a single Tool:\n",
    "The registered tool is **`execute_sql_query`** the core tool to execute SQL queries on a local SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d4a4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def execute_sql_query(query: str, db_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes a SQL query on a local SQLite database.\n",
    "    Args:\n",
    "        query (str): SQL query to execute.\n",
    "        db_path (str): Path to the SQLite database file.\n",
    "    Returns:\n",
    "        str: Results formatted as Markdown table or error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connect = sqlite3.connect(db_path)\n",
    "        cursor = connect.cursor()\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Handle SELECT queries\n",
    "        if query.strip().upper().startswith(\"SELECT\"):\n",
    "            rows = cursor.fetchall()\n",
    "            if not rows:\n",
    "                return \"No results found.\"\n",
    "\n",
    "            # Get column names\n",
    "            column_names = [description[0] for description in cursor.description]\n",
    "            # Format as Markdown table\n",
    "            markdown_table = \"  \" + \" | \".join(column_names) + \" |\\n\"\n",
    "            markdown_table += \"|\" + \"|\".join([\"---\"] * len(column_names)) + \"|\\n\"\n",
    "            for row in rows:\n",
    "                markdown_table += \"| \" + \" | \".join(str(cell) for cell in row) + \" |\\n\"\n",
    "            return markdown_table\n",
    "\n",
    "        # Handle INSERT/UPDATE/DELETE\n",
    "        else:\n",
    "            connect.commit()\n",
    "            return f\"Query executed successfully. {cursor.rowcount} rows affected.\"\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        return f\"SQL Error: {str(e)}\"\n",
    "    finally:\n",
    "        connect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ae5e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools: get_db_schema\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def get_db_schema(db_path: str = \"../data\") -> str:\n",
    "    \"\"\"\n",
    "    Retrieves simplified schema information for all SQLite databases in JSON format.\n",
    "    Args:\n",
    "        db_path (str): Path to directory containing SQLite database files. Defaults to \"../data\".\n",
    "    Returns:\n",
    "        str: JSON string containing simplified schema information.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"databases\": [],\n",
    "        \"error\": None\n",
    "    }\n",
    "\n",
    "    # Find all database files\n",
    "    db_files = []\n",
    "    for file in os.listdir(db_path):\n",
    "        if file.endswith(('.db', '.sqlite', '.sqlite3')):\n",
    "            db_files.append({\n",
    "                \"path\": os.path.join(db_path, file),\n",
    "                \"name\": os.path.basename(file)\n",
    "            })\n",
    "\n",
    "    if not db_files:\n",
    "        result[\"error\"] = \"No SQLite database files found in the specified directory.\"\n",
    "        return json.dumps(result, indent=2)\n",
    "\n",
    "    for db_file in db_files:\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_file[\"path\"])\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            database = {\n",
    "                \"name\": db_file[\"name\"],\n",
    "                \"path\": db_file[\"path\"],\n",
    "                \"total_size_mb\": round(os.path.getsize(db_file[\"path\"]) / (1024 * 1024), 2),\n",
    "                \"tables\": []\n",
    "            }\n",
    "\n",
    "            # Get all tables\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'\")\n",
    "            tables = [table[0] for table in cursor.fetchall()]\n",
    "\n",
    "            for table in tables:\n",
    "                table_info = {\n",
    "                    \"name\": table,\n",
    "                    \"columns\": [],\n",
    "                    \"indexes\": []\n",
    "                }\n",
    "\n",
    "                # Get column information\n",
    "                cursor.execute(f\"PRAGMA table_info({table})\")\n",
    "                columns = cursor.fetchall()\n",
    "                for col in columns:\n",
    "                    table_info[\"columns\"].append({\n",
    "                        \"name\": col[1],\n",
    "                        \"type\": col[2],\n",
    "                        \"nullable\": col[3] == 0\n",
    "                    })\n",
    "\n",
    "                # Get indexes\n",
    "                cursor.execute(f\"PRAGMA index_list({table})\")\n",
    "                indexes = cursor.fetchall()\n",
    "                for idx in indexes:\n",
    "                    index_info = {\n",
    "                        \"name\": idx[1],\n",
    "                        \"unique\": idx[2] == 1,\n",
    "                        \"columns\": []\n",
    "                    }\n",
    "                    cursor.execute(f\"PRAGMA index_info({idx[1]})\")\n",
    "                    idx_cols = cursor.fetchall()\n",
    "                    index_info[\"columns\"] = [col[2] for col in idx_cols]\n",
    "                    table_info[\"indexes\"].append(index_info)\n",
    "\n",
    "                database[\"tables\"].append(table_info)\n",
    "\n",
    "            result[\"databases\"].append(database)\n",
    "            conn.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            result[\"databases\"].append({\n",
    "                \"name\": db_file[\"name\"],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    return json.dumps(result, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e637776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Get Schema ===\n",
      "The database contains one table named \"shows\". Here are the columns in the \"shows\" table:\n",
      "\n",
      "1. show_id (TEXT, nullable)\n",
      "2. type (TEXT, not nullable)\n",
      "3. title (TEXT, not nullable)\n",
      "4. director (TEXT, nullable)\n",
      "5. cast (TEXT, nullable)\n",
      "6. country (TEXT, nullable)\n",
      "7. date_added (TEXT, nullable)\n",
      "8. release_year (INTEGER, nullable)\n",
      "9. rating (TEXT, nullable)\n",
      "10. duration (TEXT, nullable)\n",
      "11. listed_in (TEXT, nullable)\n",
      "12. description (TEXT, nullable)\n",
      "13. added_at (TIMESTAMP, nullable)\n",
      "\n",
      "The table has the following indexes:\n",
      "1. idx_year on release_year\n",
      "2. idx_country on country\n",
      "3. idx_type on type\n",
      "4. sqlite_autoindex_shows_1 on show_id (unique)\n",
      "\n",
      "=== Test 2: Simple Query ===\n",
      "Sure, I can help with that. But first, I need to know the structure of your database. Could you please provide the path to your SQLite database file?\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 1. Define agent state\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[HumanMessage | AIMessage | ToolMessage], add_messages]\n",
    "\n",
    "# 2. Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "tools = [get_db_schema, execute_sql_query]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 3. Define nodes\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"Call LLM with tools\"\"\"\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tool(state: AgentState):\n",
    "    \"\"\"Execute tools\"\"\"\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        if tool_call[\"name\"] == \"get_db_schema\":\n",
    "            result = get_db_schema.invoke({\"db_path\": \"../data\"})\n",
    "        else:  # execute_sql_query\n",
    "            result = execute_sql_query.invoke(tool_call[\"args\"])\n",
    "\n",
    "        outputs.append(ToolMessage(\n",
    "            content=result,\n",
    "            name=tool_call[\"name\"],\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        ))\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Decide whether to continue\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tool\"\n",
    "    return \"end\"\n",
    "\n",
    "# 4. Build graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_node(\"tool\", call_tool)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"model\",\n",
    "    should_continue,\n",
    "    {\"tool\": \"tool\", \"end\": END}\n",
    ")\n",
    "workflow.add_edge(\"tool\", \"model\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# 5. Simple test function\n",
    "def test():\n",
    "    system_prompt = \"\"\"You are a SQL assistant with these tools:\n",
    "    1. get_db_schema: Get database structure\n",
    "    2. execute_sql_query: Run SQL queries\n",
    "\n",
    "    Always get the schema first before running queries.\"\"\"\n",
    "\n",
    "    # Test 1: Get schema\n",
    "    print(\"=== Test 1: Get Schema ===\")\n",
    "    response = app.invoke({\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=system_prompt + \"\\nWhat tables exist in the database?\")\n",
    "        ]\n",
    "    })\n",
    "    print(response[\"messages\"][-1].content)\n",
    "\n",
    "    # Test 2: Simple query\n",
    "    print(\"\\n=== Test 2: Simple Query ===\")\n",
    "    response = app.invoke({\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=system_prompt + \"\\nShow me 5 movies from 2020\")\n",
    "        ]\n",
    "    })\n",
    "    print(response[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b27e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc59633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
